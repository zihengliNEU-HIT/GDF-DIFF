import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import math
from tqdm import tqdm


class DiffusionModel(nn.Module):
    """
    Diffusion model for training and sampling.
    
    Args:
        network: U-Net network
        ema_network: Exponential moving average U-Net network
        gdf_util: Gaussian diffusion utility class
        timesteps: Number of diffusion timesteps
        ema: Exponential moving average coefficient
    """
    def __init__(self, network, ema_network, gdf_util, timesteps, ema=0.999):
        super().__init__()
        self.network = network
        self.ema_network = ema_network
        self.timesteps = timesteps
        self.gdf_util = gdf_util
        self.ema = ema
        self.training_step = 0
        
        # Print model statistics
        total_params = sum(p.numel() for p in self.network.parameters())
        trainable_params = sum(p.numel() for p in self.network.parameters() if p.requires_grad)
        print(f"Total parameters: {total_params:,}")
        print(f"Trainable parameters: {trainable_params:,}")
        print(f"EMA coefficient: {ema}")
        
        # Display noise schedule information
        if hasattr(self.gdf_util, 'schedule_type'):
            print(f"Noise schedule: {self.gdf_util.schedule_type}")
        print(f"Diffusion timesteps: {timesteps}")
        
    def update_ema(self):
        """
        Update EMA network weights with dynamic learning rate.
        Uses lower EMA in early training for faster adaptation.
        """
        if self.training_step < 1000:
            current_ema = 0.95
        else:
            current_ema = min(self.ema, 0.95 + 0.05 * (1.0 - math.exp(-(self.training_step - 1000) / 5000)))
        
        with torch.no_grad():
            for ema_param, param in zip(self.ema_network.parameters(), self.network.parameters()):
                if param.requires_grad:
                    ema_param.data.mul_(current_ema).add_(param.data, alpha=1 - current_ema)
        
        if self.training_step % 1000 == 0:
            print(f"EMA update: step={self.training_step}, current_ema={current_ema:.6f}")
            
        self.training_step += 1
    
    def forward(self, x, t, condition=None, cond_vec=None):
        """
        Forward pass through the network.
        
        Args:
            x: Input noisy images
            t: Timesteps
            condition: Optional conditional input
            cond_vec: Optional conditioning vector
        Returns:
            Model output
        """
        return self.network(x, t, condition, cond_vec=cond_vec)

    @torch.no_grad()
    def generate_samples(self, conditions, device="cuda", cond_vec=None, use_ddim=True, ddim_steps=50, ddim_eta=0.0):
        """
        Generate samples using DDIM or DDPM sampling.
        
        Args:
            conditions: Conditional input images
            device: Device to run generation on
            cond_vec: Optional conditioning vector
            use_ddim: Whether to use DDIM sampling (default True)
            ddim_steps: Number of DDIM sampling steps (default 50)
            ddim_eta: DDIM stochasticity parameter (0.0=deterministic, 1.0=stochastic)
        Returns:
            Generated samples
        """
        self.ema_network.eval()
        conditions = conditions.to(device)
        if cond_vec is not None and torch.is_tensor(cond_vec):
            cond_vec = cond_vec.to(device)
        batch_size = conditions.shape[0]
        
        h, w = conditions.shape[2], conditions.shape[3]
        shape = (batch_size, 1, h, w)
        
        if use_ddim:
            print(f"Starting DDIM sampling: batch_size={batch_size}, shape={shape}, steps={ddim_steps}, eta={ddim_eta}")
            
            def model_fn(x, t, cond):
                return self.ema_network(x, t, cond, cond_vec=cond_vec)
            
            x_T = torch.randn(shape, device=device)
            
            samples = self.gdf_util.ddim_sample(
                model=model_fn,
                cond=conditions,
                steps=ddim_steps,
                eta=ddim_eta,
                x_T=x_T,
                clip_denoised=True
            )

        else:
            print(f"Starting DDPM sampling: batch_size={batch_size}, shape={shape}")
            
            def model_fn(x, t, cond):
                return self.ema_network(x, t, cond, cond_vec=cond_vec)
            
            samples = self.gdf_util.p_sample_loop(shape, model_fn, condition=conditions)
        
        print(f"Sample generation complete: shape={samples.shape}, range=[{samples.min().item():.4f}, {samples.max().item():.4f}]")
        
        return samples